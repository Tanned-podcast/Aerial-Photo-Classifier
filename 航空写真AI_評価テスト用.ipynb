{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15549511-7f9a-444c-a97f-3891f5f1c780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93001f56-0044-4deb-ab98-7dc72e5c9ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Model in Epoch 10\n",
      "TestLoss: 0.4563 TestAcc: 0.8659\n",
      "torch.Size([328, 4])\n",
      "(328,)\n",
      "[[143  17   0   0]\n",
      " [  4 114   0   0]\n",
      " [  5   3   1   1]\n",
      " [  4  10   0  26]]\n",
      " \n",
      "Testing Complete!!!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "Channels=4\n",
    "IMG_SIZE=224\n",
    "epochlist=[10]\n",
    "\n",
    "Classes = [\"higainashi\", \"houdo\", \"kanbotsu\", \"rokatahoukai\"]\n",
    "ClassNum = len(Classes)\n",
    "\n",
    "testpath=r\"C:\\Users\\AKIZUKI\\JupyterProjects\\QGISedited\\train\"\n",
    "savepath=r\"C:\\Users\\AKIZUKI\\JupyterProjects\\AerialPhoto_savedmodel\"\n",
    "\n",
    "'''\n",
    "PytorchではDataloaderという,膨大なデータセットからでもメモリを圧迫せずに取り出せてforループにも対応するための枠組みがある\n",
    "データセットをDataloaderが引っ張ってこれるような形式にするためにMyDataset(torch.utils.data.Dataset)というクラスを作れば，\n",
    "あとはそのメソッドをtorch.utils.data.Datasetが勝手に使用してデータを加工してくれる\n",
    "__init__, __getitem__, __len__をクラス内で必ず定義しなければならない\n",
    "Dataloader内のデータはバッチごとにまとめられる\n",
    "'''\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root: str, transforms, Classes) -> None:\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.Classes = Classes\n",
    "        #globは複数のファイルのパスをまとめて取得する\n",
    "        #訓練と訓練白黒の二個下のディレクトリから画像を取得\n",
    "        self.data = list(sorted(Path(root).glob(\"*\\*\")))\n",
    "        self.data2 = list(sorted(Path(root+\"binary\").glob(\"*\\*\")))\n",
    "\n",
    "\n",
    "\n",
    "    # ここで取り出すデータを指定している\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        data = self.data[index]\n",
    "        data2 = self.data2[index]\n",
    "\n",
    "        img1 = cv2.imread(str(data))\n",
    "        img1 = cv2.resize(img1, (IMG_SIZE, IMG_SIZE))\n",
    "        img2_tmp = cv2.imread(str(data2))\n",
    "\n",
    "        # グレースケールに変換\n",
    "        img2_tmp = cv2.cvtColor(img2_tmp,cv2.COLOR_BGR2GRAY)\n",
    "        # 2値化\n",
    "        ret,img2 = cv2.threshold(img2_tmp, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "        img2 = cv2.resize(img2, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        #img1のテンソルとimg2のテンソルをチャンネル方向(dim0)に結合\n",
    "        cat_img = torch.cat((TF.to_tensor(img1), TF.to_tensor(img2)), dim=0)\n",
    "\n",
    "        # データの変形 (transforms)\n",
    "        transformed_img = self.transforms(cat_img)\n",
    "\n",
    "        #ラベル貼り：dataというパスを/で区切ってリストにし，クラス名のところをラベルに格納\n",
    "        #クラス名は文字列なので，self.Classesの要素と比較して一致するところの番号をラベルとする\n",
    "        label = str(data).split(\"\\\\\")[-2]\n",
    "        label = torch.tensor(self.Classes.index(label))\n",
    "\n",
    "        return transformed_img, label\n",
    "\n",
    "    # この method がないと DataLoader を呼び出す際にエラーを吐かれる\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "#入力データに施す処理\n",
    "transforms = v2.Compose([\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0,0,0,0], std=[0.2, 0.2, 0.2, 0.2]),\n",
    "])\n",
    "\n",
    "testset= MyDataset(root=testpath, transforms=transforms, Classes=Classes)\n",
    "\n",
    "testloader = DataLoader(dataset=testset,batch_size=len(testset),shuffle=True)\n",
    "print(len(testloader))\n",
    "\n",
    "resnet50 = models.resnet50()\n",
    "\n",
    "#modify first layer so it expects 4 input channels; all other parameters unchanged\n",
    "resnet50.conv1 = torch.nn.Conv2d(Channels,64,kernel_size = (7,7),stride = (2,2), padding = (3,3), bias = False)\n",
    "#modifying final layer\n",
    "resnet50.fc = nn.Linear(2048,ClassNum)\n",
    "\n",
    "#lossfunction&optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def evaluate(testloader, model, loss_fn, optimizer):\n",
    "    size_test = len(testloader.dataset)\n",
    "    test_loss, test_correct = 0, 0\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    model.eval()\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            test_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        test_correct /= size_test\n",
    "\n",
    "    print(f'TestLoss: {test_loss:.4f} TestAcc: {test_correct:.4f}')\n",
    "\n",
    "    #ndarrayにするため、ラベルyと推測結果predをgpuからcpuへ返す\n",
    "    y=y.to(cpu)\n",
    "    pred=pred.to(cpu)\n",
    "   \n",
    "    y=np.array(y)\n",
    "\n",
    "    #predは各クラスの確率になってる（onehotに近い）ので実際のクラス番号に戻す\n",
    "    pred_class=pred.argmax(1)\n",
    "    pred_class=np.array(pred_class)\n",
    "    \n",
    "    \n",
    "    #テストデータの混同行列を計算し可視化\n",
    "    #scikitlearnの混同行列はラベルをonehotではなく実際のクラス番号にする必要がある\n",
    "    #混同行列の見方は行が正解ラベルのクラス列が推定クラス\n",
    "    print(confusion_matrix(y, pred_class))\n",
    "    print(\" \")\n",
    "\n",
    "for e in epochlist:\n",
    "    #モデル構築\n",
    "    modelpath = Path(savepath+\"\\\\\"+str(e)+\"\\model_weights.pth\")\n",
    "    epochmodel = resnet50\n",
    "    epochmodel.load_state_dict(torch.load(modelpath))\n",
    "    #GPUにニューラルネットワークを渡す\n",
    "    epochmodel=epochmodel.to(device)\n",
    "\n",
    "    print(\"Model in Epoch\", e)\n",
    "    #テストデータで評価\n",
    "    evaluate(testloader, epochmodel, loss_fn, optimizer)\n",
    "\n",
    "print('Testing Complete!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
